# Log Analysis Project

Final project of Intro to Programming Nanodegree Program

## Description 

The aim of this project is to make reports from a PostgreSQL relational database containing information about articles and their logs.
Python is used to access the database and write reports to a text file. The following reports are generated by the Python Program:

1. **What are the most popular three articles of all time?** Which articles have been accessed the most? Present this information as a sorted list with the most popular article at the top.

2. **Who are the most popular article authors of all time?** That is, when you sum up all of the articles each author has written, which authors get the most page views? Present this as a sorted list with the most popular author at the top.

3. **On which days did more than 1% of requests lead to errors?** The log table includes a column status that indicates the HTTP status code that the news site sent to the user's browser. (Refer back to this lesson if you want to review the idea of HTTP status codes.)

The program uses the psycopg2 python library to connect to PostgreSQL. Moreover, the program runs 3 sql queries in order to generate the reports. Then this queries are sent to the *write_to_file* function for the purpose of appropriately formating the result of these queries and write this results to the text file output.txt.

## Prerequisites

In order to run the program you need the following:

* A linux machine
* Python3
* Install the python package psycopg2
* A working installation of PostgreSQL
* A PostgreSQL's user with name 'vagrant'
* A database with name 'news'
* Create and populate the schema of the database news with the following script (provided by Udacity): 
  [news database](https://d17h27t6h515a5.cloudfront.net/topher/2016/August/57b5f748_newsdata/newsdata.zip)
* Create the following views:
  ```sql
  create view articles_in_log as
  select regexp_replace(path, '/article/', '') as title from log WHERE path like '%article%';

  create view articles_transformed as
  select title, replace(regexp_replace(lower(title), '[^a-z0-9 ]', ''), ' ', '-') as title_transformed
  from articles;

  create view views_articles as
  select B.title, count(*) as views
  from articles_in_log A, articles_transformed B
  where
  position(A.title in B.title_transformed) > 0
  group by B.title;

  create view views_authors as
  select A.author as author_id, sum(B.views) as views
  from articles A, views_articles B
  where A.title = B.title
  group by A.author
  order by views desc;

  create view summary_http_status_ok_code as
  select time::date as date, status, count(*) as total
  from log
  where status = '200 OK'
  group by date, status;

  create view summary_http_status_error_code as
  select time::date as date, status, count(*) as total
  from log
  where status = '404 NOT FOUND'
  group by date, status;

  create view error_percentage as
  select A.date, (cast(B.total as numeric) / cast(A.total + B.total as numeric))*100.0 as error
  from summary_http_status_ok_code A, summary_http_status_error_code B
  where
  A.date = B.date;

  ```

## Installation

In order to install the program, you must run the following command in the terminal:

```bash
git clone https://github.com/ricardoues/log-analysis-project.git 
```

## Usage

To use the program, you must change the current directory to the directory log-analysis-project and run either of the following commands: 

```bash
python3 log_analysis.py
```

```bash
python3 log_analysis.py
```

The text file output.txt containing the reports should have generated in the directory log-analysis-project.


## Authors

* **Ricardo Rios** - *Initial work* - [Ricardo Rios](https://github.com/ricardoues)

## License

This project is licensed under the GNU GPL v3.0 License - see the [gpl-3.0.md](gpl-3.0.md) file for details

## Acknowledgments

* I would like to express my special thanks of Udacity's team to give me this great opportunity to learn.


