# Log Analysis Project

Final project of Intro to Programming Nanodegree Program

## Description 

The aim of this project is to make reports from a PostgreSQL relational database containing information about articles and their logs.
Python is used to access the database and write reports to a text file. The following reports are generated by the Python Program:

1. **What are the most popular three articles of all time?** Which articles have been accessed the most? Present this information as a sorted list with the most popular article at the top.

2. **Who are the most popular article authors of all time?** That is, when you sum up all of the articles each author has written, which authors get the most page views? Present this as a sorted list with the most popular author at the top.

3. **On which days did more than 1% of requests lead to errors?** The log table includes a column status that indicates the HTTP status code that the news site sent to the user's browser. (Refer back to this lesson if you want to review the idea of HTTP status codes.)

The program uses the psycopg2 python library to connect to PostgreSQL. Moreover, the program runs 3 sql queries in order to generate the reports. Then this queries are sent to the *write_to_file* function for the purpose of appropriately formating the result of these queries and write this results to the text file output.txt.

## Prerequisites

In order to run the program you need the following:

* A linux machine
* Python3
* Install the python package psycopg2
* A working installation of PostgreSQL
* A PostgreSQL's user with name 'vagrant'
* A database with name 'news'
* Download the following zip file (provided by Udacity): 
  [news database](https://d17h27t6h515a5.cloudfront.net/topher/2016/August/57b5f748_newsdata/newsdata.zip)
* Unzip the previous downloaded file
* Run the following command to create and populate tables on the database news: 
  ```bash
  psql -d news -f newsdata.sql
  ```
* Create the following views:
  ```sql
create view views_articles as
select title, count(*) as views 
from log  inner join articles on (log.path = concat('/article/', articles.slug))
where status = '200 OK' 
group by title;

create view views_authors as
select articles.author as author_id, sum(views) as views
from articles inner join views_articles on (articles.title = views_articles.title) 
group by author_id;

create view error_percentage as
select time::date as date, 
round( (100.0 * 
cast(sum(case when status = '404 NOT FOUND' then 1 else 0 end) as numeric) / 
cast(count(status) as numeric)), 2) as error
from log 
group by date;

  ```

## Installation

In order to install the program, you must run the following command in the terminal:

```bash
git clone https://github.com/ricardoues/log-analysis-project.git 
```

The above command creates the folder log-analysis-project. Within this folder there is a python file log_analysis.py, you must 
change the following code according to the configuration of your machine:

```python
try:
    conn = psycopg2.connect("dbname='news' user='vagrant' \
                             host='localhost' \
                             password='badpassword'")
```

**Note**: You must provide a password even though you can access to your PostgreSQL databases without a password. 
 


## Usage

To use the program, you must change the current directory to the directory log-analysis-project and run either of the following commands: 

```bash
python3 log_analysis.py
```

```bash
./log_analysis.py
```

The text file output.txt containing the reports should have generated in the directory log-analysis-project.


## Authors

* **Ricardo Rios** - *Initial work* - [Ricardo Rios](https://github.com/ricardoues)

## License

This project is licensed under the GNU GPL v3.0 License - see the [gpl-3.0.md](gpl-3.0.md) file for details

## Acknowledgments

* I would like to express my special thanks to Udacity team to give me this great opportunity to learn.


